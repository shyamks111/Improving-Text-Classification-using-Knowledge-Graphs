{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KGE_DataPrep.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_KkhyPUQlDo",
        "colab_type": "text"
      },
      "source": [
        "Data Preparation for KGE datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-VkAurw9vLst",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240
        },
        "outputId": "b7244154-4d2f-483b-91d9-c0749d7c2aba"
      },
      "source": [
        "pip install wikipedia2vec"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: wikipedia2vec in /usr/local/lib/python3.6/dist-packages (1.0.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from wikipedia2vec) (4.41.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from wikipedia2vec) (1.12.0)\n",
            "Requirement already satisfied: marisa-trie in /usr/local/lib/python3.6/dist-packages (from wikipedia2vec) (0.7.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from wikipedia2vec) (1.4.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from wikipedia2vec) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from wikipedia2vec) (0.16.0)\n",
            "Requirement already satisfied: lmdb in /usr/local/lib/python3.6/dist-packages (from wikipedia2vec) (0.98)\n",
            "Requirement already satisfied: mwparserfromhell in /usr/local/lib/python3.6/dist-packages (from wikipedia2vec) (0.5.4)\n",
            "Requirement already satisfied: jieba in /usr/local/lib/python3.6/dist-packages (from wikipedia2vec) (0.42.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from wikipedia2vec) (1.18.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJ2_LiUOsvMP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from wikipedia2vec import Wikipedia2Vec\n",
        "wiki2vec = Wikipedia2Vec.load(\"enwiki_20180420_100d.pkl\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bmnhB7b3Qjur",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "if dataset == 1:\n",
        "  df = pd.read_csv(\"drugsComTest_raw.csv\")\n",
        "  conditions = df_new['condition'].value_counts()[:10].index.to_list()\n",
        "  df_int = pd.DataFrame(columns = df_new.columns.tolist())\n",
        "  for condition in conditions:\n",
        "    df_int =  pd.concat([df_int,d[df['condition']==condition]])\n",
        "  drugs = []\n",
        "  drug_list = df_int['drugName'].values\n",
        "  drug_list = list(drug_list)\n",
        "  for drug in drug_list:\n",
        "    drugs.append(drug)\n",
        "  drug_list = list(drugs)\n",
        "  drug_set = set(drug_list)\n",
        "  count = 0\n",
        "  drug_dict={}\n",
        "  drug_list_i = []\n",
        "  for drug in drug_set:\n",
        "    try:\n",
        "      drug_dict[drug] = np.array(wiki2vec.get_entity_vector(drug))\n",
        "    except KeyError:\n",
        "      count = count + 1\n",
        "      drug_list_i.append(drug) \n",
        "\n",
        "  drug_set_new = set(drug_list_i)\n",
        "  df_remove = pd.DataFrame(columns = df_int.columns.tolist())\n",
        "  for drug in drug_set_new:\n",
        "    df_remove =  pd.concat([df_remove,df_int[df_int['drugName']==drug]]) \n",
        "  df_int = df_int[~df_int.isin(df_remove)].dropna()\n",
        "  df_int = df_int.loc[:,['drugName','condition','review']]\n",
        "  df_final = pd.DataFrame(columns = df_int.columns.tolist())\n",
        "  for condition in conditions:\n",
        "    df_final =  pd.concat([df_final,df_int[df_int['condition']==condition][:500]]) \n",
        "  category_dict = {\"Insomnia\":0,\"ADHD\":1,\"Obesity\":2,\"Weight Loss\":3,\"Acne\":4,\"Depression\":5,\"Bipolar Disorde\":6,\"Anxiety\":7,\"Birth Control\":8,\"Pain\":9}\n",
        "  df_final[\"Label\"] = df_final[\"condition\"].map(category_dict)\n",
        "  df_final = df_final.sample(frac=1)\n",
        "  df_final.columns = ['drugName','condition','review','Labels']\n",
        "  df_final.to_csv('med_500.csv', index = False)\n",
        "elif dataset == 2: \n",
        "  df = pd.read_csv(\"wiki_movie_plots_deduped.csv\")\n",
        "  df_new = df.loc[df['Director'] != \"Unknown\"]\n",
        "  df_new = df_new.loc[df_new['Genre'] != \"unknown\"]\n",
        "  genres = df_new['Genre'].value_counts()[:5].index.to_list()\n",
        "  df_int = pd.DataFrame(columns = df_new.columns.tolist())\n",
        "  for genre in genres:\n",
        "    df_int =  pd.concat([df_int,df_new[df_new['Genre']==genre]]) \n",
        "  for index,row in df_int.iterrows():\n",
        "    row['Director'] = row['Director'].split(\",\")[0]\n",
        "  director_list1 = df_int['Director']\n",
        "  directors = []\n",
        "  director_list = director_list1.values\n",
        "  director_list = list(director_list)\n",
        "  for director in director_list:\n",
        "    directors.append(director.split(',')[0])\n",
        "  director_list = list(directors)\n",
        "  director_set = set(director_list)\n",
        "  df_int['Directors'] = directors\n",
        "  count = 0\n",
        "  director_dict={}\n",
        "  director_list_i = []\n",
        "  for director in director_set:\n",
        "    try:\n",
        "      director_dict[director] = np.array(wiki2vec.get_entity_vector(director))\n",
        "    except KeyError:\n",
        "      count = count + 1\n",
        "      director_list_i.append(director)\n",
        "\n",
        "  director_set_new = set(director_list_i)\n",
        "  df_remove = pd.DataFrame(columns = df_int.columns.tolist())\n",
        "  for director in director_set_new:\n",
        "    df_remove =  pd.concat([df_remove,df_int[df_int['Director']==director]]) \n",
        "  df_int = df_int[~df_int.isin(df_remove)].dropna()\n",
        "  df_int = df_int.loc[:,['Title','Genre','Plot','Directors']]\n",
        "  df_final = pd.DataFrame(columns = df_int.columns.tolist())\n",
        "  for genre in genres:\n",
        "    df_final =  pd.concat([df_final,df_int[df_int['Genre']==genre][:700]]) \n",
        "  category_dict = {\"drama\":0,\"comedy\":1,\"horror\":2,\"action\":3,\"thriller\":4}\n",
        "  df_final[\"Labels\"] = df_final[\"Genre\"].map(category_dict)\n",
        "  df_final = df_final.sample(frac=1)\n",
        "  df_final = df_final[['Title','Directors','Genre','Plot','Labels']]\n",
        "  df_final.columns = ['Title','Director','Genre','Plot','Labels']\n",
        "  df_final.to_csv('movie_genre5.csv', index = False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}

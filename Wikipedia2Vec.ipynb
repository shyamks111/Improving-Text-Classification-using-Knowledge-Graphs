{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Wiki2Vec.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "npYRo_7LiwmD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 591
        },
        "outputId": "6ffb172d-937d-4205-9cbb-9a4589f56dba"
      },
      "source": [
        "!pip install wikipedia2vec"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting wikipedia2vec\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d8/88/751037c70ca86581d444824e66bb799ef9060339a1d5d1fc1804c422d7cc/wikipedia2vec-1.0.4.tar.gz (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 2.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from wikipedia2vec) (7.1.2)\n",
            "Requirement already satisfied: jieba in /usr/local/lib/python3.6/dist-packages (from wikipedia2vec) (0.42.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from wikipedia2vec) (0.16.0)\n",
            "Requirement already satisfied: lmdb in /usr/local/lib/python3.6/dist-packages (from wikipedia2vec) (0.98)\n",
            "Collecting marisa-trie\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/20/95/d23071d0992dabcb61c948fb118a90683193befc88c23e745b050a29e7db/marisa-trie-0.7.5.tar.gz (270kB)\n",
            "\u001b[K     |████████████████████████████████| 276kB 17.5MB/s \n",
            "\u001b[?25hCollecting mwparserfromhell\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/23/03/4fb04da533c7e237c0104151c028d8bff856293d34e51d208c529696fb79/mwparserfromhell-0.5.4.tar.gz (135kB)\n",
            "\u001b[K     |████████████████████████████████| 143kB 19.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from wikipedia2vec) (1.18.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from wikipedia2vec) (1.4.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from wikipedia2vec) (1.15.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from wikipedia2vec) (4.41.1)\n",
            "Building wheels for collected packages: wikipedia2vec, marisa-trie, mwparserfromhell\n",
            "  Building wheel for wikipedia2vec (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wikipedia2vec: filename=wikipedia2vec-1.0.4-cp36-cp36m-linux_x86_64.whl size=4581849 sha256=1c07a6ac5df54354f138cdc2112896a7bd4218ae6a8aaeabbaa2771e415bc04d\n",
            "  Stored in directory: /root/.cache/pip/wheels/16/e7/02/852c8ce366cc10adcf5d43c6471bbf926dd15c277578c13184\n",
            "  Building wheel for marisa-trie (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for marisa-trie: filename=marisa_trie-0.7.5-cp36-cp36m-linux_x86_64.whl size=862153 sha256=89294bea02408af6ff397a5707759ae469c6fdea6b2495767727e43908978b71\n",
            "  Stored in directory: /root/.cache/pip/wheels/45/24/79/022624fc914f0e559fe8a1141aaff1f9df810905a13fc75d57\n",
            "  Building wheel for mwparserfromhell (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mwparserfromhell: filename=mwparserfromhell-0.5.4-cp36-cp36m-linux_x86_64.whl size=183766 sha256=13fd990eafca73b724baa6e12faef30d78e586f0fce00fae44caad5dccbea770\n",
            "  Stored in directory: /root/.cache/pip/wheels/2a/76/d5/7088b941df3b362c45dd7912dd05314bc034751ec9cbca9a75\n",
            "Successfully built wikipedia2vec marisa-trie mwparserfromhell\n",
            "Installing collected packages: marisa-trie, mwparserfromhell, wikipedia2vec\n",
            "Successfully installed marisa-trie-0.7.5 mwparserfromhell-0.5.4 wikipedia2vec-1.0.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJ2_LiUOsvMP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# File \"enwiki_20180420_100d.pkl\" is available in the Wikipedia2Vec website\n",
        "from wikipedia2vec import Wikipedia2Vec\n",
        "wiki2vec = Wikipedia2Vec.load(\"enwiki_20180420_100d.pkl\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MXg7ScEs8ARR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 999
        },
        "outputId": "52330b6a-fd0b-43c1-a39e-63ec3b9002e7"
      },
      "source": [
        "import pandas as pd\n",
        "dataset = 2\n",
        "\n",
        "if dataset == 1:\n",
        "  df = pd.read_csv(\"drugsComTest_raw.csv\")\n",
        "elif dataset == 2:\n",
        "  df = pd.read_csv(\"wiki_movie_plots_deduped.csv\")\n",
        "#elif dataset == 3:\n",
        "#  df = pd.read_csv(\"uci_news.csv\")\n",
        "\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>TITLE</th>\n",
              "      <th>URL</th>\n",
              "      <th>PUBLISHER</th>\n",
              "      <th>CATEGORY</th>\n",
              "      <th>STORY</th>\n",
              "      <th>HOSTNAME</th>\n",
              "      <th>TIMESTAMP</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2894.0</td>\n",
              "      <td>Zac Efron - Zac Efron Open To High School Musi...</td>\n",
              "      <td>http://www.contactmusic.com/story/zac-efron-op...</td>\n",
              "      <td>Contactmusic.com</td>\n",
              "      <td>e</td>\n",
              "      <td>dEwcrt6LPSpnQZMj6PUU87nPXmo7M</td>\n",
              "      <td>www.contactmusic.com</td>\n",
              "      <td>1.394530e+12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2273.0</td>\n",
              "      <td>HBO Releases Third \"Game Of Thrones\" Season 4 ...</td>\n",
              "      <td>http://www.newnownext.com/hbo-releases-another...</td>\n",
              "      <td>NewNowNext</td>\n",
              "      <td>e</td>\n",
              "      <td>doklLt-bdL5ggOMQ_e6SbdaJYJr5M</td>\n",
              "      <td>www.newnownext.com</td>\n",
              "      <td>1.394520e+12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>12232.0</td>\n",
              "      <td>South Nassau Communities Hospital warns thousa...</td>\n",
              "      <td>http://longisland.news12.com/news/south-nassau...</td>\n",
              "      <td>News 12 Long Island</td>\n",
              "      <td>m</td>\n",
              "      <td>dXpdjLsCw2zsmsMeDAz1dME8EtoKM</td>\n",
              "      <td>longisland.news12.com</td>\n",
              "      <td>1.394723e+12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4386.0</td>\n",
              "      <td>Libya PM ousted by parliament</td>\n",
              "      <td>http://www.belfasttelegraph.co.uk/news/world-n...</td>\n",
              "      <td>Belfast Telegraph</td>\n",
              "      <td>b</td>\n",
              "      <td>dZN_cm41wSN59aMjra4bdYw_-ofgM</td>\n",
              "      <td>www.belfasttelegraph.co.uk</td>\n",
              "      <td>1.394562e+12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>8204.0</td>\n",
              "      <td>Japanese researcher backtracks on 'breakthroug...</td>\n",
              "      <td>http://www.trust.org/item/20140310131350-zugvm...</td>\n",
              "      <td>Thomson Reuters Foundation</td>\n",
              "      <td>m</td>\n",
              "      <td>d9bc8RAo3Q2yAKM7_UciU5-WfbkdM</td>\n",
              "      <td>www.trust.org</td>\n",
              "      <td>1.394626e+12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2795</th>\n",
              "      <td>1496.0</td>\n",
              "      <td>Senator, safety advocates press NHTSA in wake ...</td>\n",
              "      <td>http://www.detroitnews.com/article/20140307/AU...</td>\n",
              "      <td>The Detroit News</td>\n",
              "      <td>t</td>\n",
              "      <td>d6oHu5PfuD_389MzHgrh61KXagXnM</td>\n",
              "      <td>www.detroitnews.com</td>\n",
              "      <td>1.394503e+12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2796</th>\n",
              "      <td>4553.0</td>\n",
              "      <td>Colorado made $3.5m 'pot' tax in January</td>\n",
              "      <td>http://manilastandardtoday.com/2014/03/11/colo...</td>\n",
              "      <td>Manila Standard Today</td>\n",
              "      <td>b</td>\n",
              "      <td>d__jcKruuebDhTMfkhbUJpI3MBjEM</td>\n",
              "      <td>manilastandardtoday.com</td>\n",
              "      <td>1.394566e+12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2797</th>\n",
              "      <td>1123.0</td>\n",
              "      <td>Warm, wet climate aids Mongol Empire's expansi...</td>\n",
              "      <td>http://english.peopledaily.com.cn/202936/85614...</td>\n",
              "      <td>People's Daily Online</td>\n",
              "      <td>t</td>\n",
              "      <td>dYRPyd6HqIPIS_MW7vO0rcnAOciKM</td>\n",
              "      <td>english.peopledaily.com.cn</td>\n",
              "      <td>1.394499e+12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2798</th>\n",
              "      <td>133.0</td>\n",
              "      <td>US STOCKS-Wall Street edges lower after record...</td>\n",
              "      <td>http://in.reuters.com/article/2014/03/10/marke...</td>\n",
              "      <td>Reuters</td>\n",
              "      <td>b</td>\n",
              "      <td>dchKRTV8vDviyCMH_lfUDTuFThh_M</td>\n",
              "      <td>in.reuters.com</td>\n",
              "      <td>1.394472e+12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2799</th>\n",
              "      <td>15405.0</td>\n",
              "      <td>Tequila Plant May Be Good For Diabetics</td>\n",
              "      <td>http://www.science20.com/news_articles/tequila...</td>\n",
              "      <td>Science 2.0</td>\n",
              "      <td>m</td>\n",
              "      <td>d-XmXYsfzUJL5-Mon98rVnC3JBbAM</td>\n",
              "      <td>www.science20.com</td>\n",
              "      <td>1.395066e+12</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2800 rows × 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           ID  ...     TIMESTAMP\n",
              "0      2894.0  ...  1.394530e+12\n",
              "1      2273.0  ...  1.394520e+12\n",
              "2     12232.0  ...  1.394723e+12\n",
              "3      4386.0  ...  1.394562e+12\n",
              "4      8204.0  ...  1.394626e+12\n",
              "...       ...  ...           ...\n",
              "2795   1496.0  ...  1.394503e+12\n",
              "2796   4553.0  ...  1.394566e+12\n",
              "2797   1123.0  ...  1.394499e+12\n",
              "2798    133.0  ...  1.394472e+12\n",
              "2799  15405.0  ...  1.395066e+12\n",
              "\n",
              "[2800 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hj1DR4R9KepX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if dataset == 1:\n",
        "  category_dict = {\"Insomnia\":0,\"ADHD\":1,\"Obesity\":2,\"Weight Loss\":3,\"Acne\":4,\"Depression\":5,\"Bipolar Disorde\":6,\"Anxiety\":7,\"Birth Control\":8,\"Pain\":9}\n",
        "  df[\"Label\"] = df[\"condition\"].map(category_dict)\n",
        "elif dataset == 2:  \n",
        "  for index,row in df.iterrows():\n",
        "    row['Director'] = row['Director'].split(\",\")[0]\n",
        "# elif dataset == 3:\n",
        "#   df = df.loc[:,[\"TITLE\",\"PUBLISHER\",\"CATEGORY\"]]\n",
        "#   category_dict = {\"e\":0,\"t\":1,\"b\":2,\"m\":3}\n",
        "#   df.columns = [\"Text\",\"Publisher\",\"Category\"]\n",
        "#   df[\"Label\"] = df[\"Category\"].map(category_dict)\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uGdQB9ATKso0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "4e232836-8960-4fe9-bb58-26ffa18ffa99"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Publisher</th>\n",
              "      <th>Category</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Zac Efron - Zac Efron Open To High School Musi...</td>\n",
              "      <td>Contactmusic.com</td>\n",
              "      <td>e</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>HBO Releases Third \"Game Of Thrones\" Season 4 ...</td>\n",
              "      <td>NewNowNext</td>\n",
              "      <td>e</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>South Nassau Communities Hospital warns thousa...</td>\n",
              "      <td>News 12 Long Island</td>\n",
              "      <td>m</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Libya PM ousted by parliament</td>\n",
              "      <td>Belfast Telegraph</td>\n",
              "      <td>b</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Japanese researcher backtracks on 'breakthroug...</td>\n",
              "      <td>Thomson Reuters Foundation</td>\n",
              "      <td>m</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2795</th>\n",
              "      <td>Senator, safety advocates press NHTSA in wake ...</td>\n",
              "      <td>The Detroit News</td>\n",
              "      <td>t</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2796</th>\n",
              "      <td>Colorado made $3.5m 'pot' tax in January</td>\n",
              "      <td>Manila Standard Today</td>\n",
              "      <td>b</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2797</th>\n",
              "      <td>Warm, wet climate aids Mongol Empire's expansi...</td>\n",
              "      <td>People's Daily Online</td>\n",
              "      <td>t</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2798</th>\n",
              "      <td>US STOCKS-Wall Street edges lower after record...</td>\n",
              "      <td>Reuters</td>\n",
              "      <td>b</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2799</th>\n",
              "      <td>Tequila Plant May Be Good For Diabetics</td>\n",
              "      <td>Science 2.0</td>\n",
              "      <td>m</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2800 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   Text  ... Label\n",
              "0     Zac Efron - Zac Efron Open To High School Musi...  ...     0\n",
              "1     HBO Releases Third \"Game Of Thrones\" Season 4 ...  ...     0\n",
              "2     South Nassau Communities Hospital warns thousa...  ...     3\n",
              "3                         Libya PM ousted by parliament  ...     2\n",
              "4     Japanese researcher backtracks on 'breakthroug...  ...     3\n",
              "...                                                 ...  ...   ...\n",
              "2795  Senator, safety advocates press NHTSA in wake ...  ...     1\n",
              "2796           Colorado made $3.5m 'pot' tax in January  ...     2\n",
              "2797  Warm, wet climate aids Mongol Empire's expansi...  ...     1\n",
              "2798  US STOCKS-Wall Street edges lower after record...  ...     2\n",
              "2799            Tequila Plant May Be Good For Diabetics  ...     3\n",
              "\n",
              "[2800 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ULAjiH8Rg49h",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "if dataset == 1:\n",
        "  drug_list = df['drugName']\n",
        "  drug_set = set(drug_list)\n",
        "  drug_dict = {}\n",
        "  for drug in drug_set:\n",
        "    try:\n",
        "      drug_dict[drug] = np.array(wiki2vec.get_entity_vector(drug))\n",
        "    except KeyError:\n",
        "      pass\n",
        "elif dataset == 2:\n",
        "  director_list = df['Director']\n",
        "  director_set = set(director_list)\n",
        "  director_dict = {}\n",
        "  for director in director_set:\n",
        "    try:\n",
        "      director_dict[director] = np.array(wiki2vec.get_entity_vector(director))\n",
        "    except KeyError:\n",
        "      print(director)\n",
        "      pass\n",
        "# elif dataset == 3:\n",
        "#   publisher_list = df['Publisher']\n",
        "#   publisher_set = set(publisher_list)\n",
        "#   publisher_dict = {}\n",
        "#   for publisher in publisher_set:\n",
        "#     try:\n",
        "#       publisher_dict[publisher] = np.array(wiki2vec.get_entity_vector(publisher))\n",
        "#     except KeyError:\n",
        "#       print(publisher)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hIEuCLzKht4t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "\n",
        "if dataset == 1:\n",
        "  with open('drug.pickle', 'wb') as handle:\n",
        "      pickle.dump(drug_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "elif dataset == 2:\n",
        "  with open('director.pickle', 'wb') as handle:\n",
        "      pickle.dump(director_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "# elif dataset == 3:\n",
        "#   with open('publisher.pickle', 'wb') as handle:\n",
        "#       pickle.dump(publisher_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}